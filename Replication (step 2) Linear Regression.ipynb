{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear Regression\n",
    "\n",
    "With the features mentioned above in this part, we applied\n",
    "the linear regression to the training dataset. The features\n",
    "are rCount, tlen, tpol, tsub. The label is set to (review_star - (uAvg+bAvg)/2.0) \n",
    "where $y_i$ is review $star_i$ and $\\epsilon_i$ is\n",
    "(uAvg+bAvg)/2.0. With the features and labels, the linear\n",
    "regression is applied by using numpy.linalg.lstsq.\n",
    "Then, the (features·θ+(uAvg+bAvg)/2.0) is applied, which\n",
    "is the equation mentioned above, to do the prediction for\n",
    "those users and businesses seen in training dataset. Otherwise,\n",
    "use (feature·θ+averageRate) for prediction where averageRate\n",
    "is the average rating stars for all training reviews.\n",
    "Furthermore, in this model, we also add a correction to\n",
    "set the prediction value equal to 5.0 if it’s calculated value\n",
    "is larger than 5.0, since the rating stars will never be larger\n",
    "than 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(\"X_train_spec.parquet\", engine=\"pyarrow\")\n",
    "y_train = pd.read_parquet(\"y_train_spec.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features (training)\n",
    "\n",
    "\n",
    "X_train = X_train[['rCount', 'tlen', 'tpol', 'tsub']]\n",
    "#y_train = y_train_spec - (X_train_spec.uAvg + X_train_spec.bAvg)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model\n",
    "\n",
    "#m = np.linalg.lstsq(X_train_reg, y_train_reg)\n",
    "# use scikit-learn instead of numpy\n",
    "\n",
    "regr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_parquet(\"X_test_spec.parquet\", engine=\"pyarrow\")\n",
    "y_test = pd.read_parquet(\"y_test_spec.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features (test)\n",
    "\n",
    "X_test = X_test[['rCount', 'tlen', 'tpol', 'tsub']]\n",
    "#y_test_reg = y_test_spec - (X_test_spec.uAvg + X_test_spec.bAvg)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error: {}\".format(round(score, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
